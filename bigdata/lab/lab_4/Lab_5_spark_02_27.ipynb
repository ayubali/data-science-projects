{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.77.72:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdd = sc.textFile('book.txt')\n",
    "rdd0=  sc.parallelize(list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 7, 6, 5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd0.top(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd0.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg EBook of English Coins and Tokens, by '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('book.txt')\n",
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'Project',\n",
       "  'Gutenberg',\n",
       "  'EBook',\n",
       "  'of',\n",
       "  'English',\n",
       "  'Coins',\n",
       "  'and',\n",
       "  'Tokens,',\n",
       "  'by'],\n",
       " ['Llewellynn', 'Jewitt', 'and', 'Barclay', 'V.', 'Head'],\n",
       " []]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x : x.split()) \\\n",
    "    .take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Project', 'Gutenberg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda x : x.split()) \\\n",
    "    .take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bronx', [('the', 2104), ('of', 1631), ('and', 1277)]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "def mapper(_, rows):\n",
    "    for row in rows:\n",
    "        for word in row.split():\n",
    "            yield word\n",
    "\n",
    "\n",
    "\n",
    "rdd.mapPartitionsWithIndex(mapper) \\\n",
    "    .map(lambda x: (x,1)) \\\n",
    "    .groupByKey() \\\n",
    "    .mapValues(lambda x: sum(x)) \\\n",
    "    .map(lambda x: ('bronx',x)) \\\n",
    "    .groupByKey() \\\n",
    "    .flatMap(lambda g: (g[0],nlargest(3,g[1],key=lambda e:e[1]))) \\\n",
    "    .collect()\n",
    "\n",
    "\n",
    "\n",
    "#rdd.mapPartitionsWithIndex(mapper) \\\n",
    "#    .map(lambda x: (x,1)) \\\n",
    "#    .groupByKey() \\\n",
    "#    .mapValues(lambda x: sum(x)) \\\n",
    "#    .collect()\n",
    "\n",
    "#rdd.mapPartitionsWithIndex(mapper) \\\n",
    "#    .map(lambda x: (x,1)) \\\n",
    "#    .reduceByKey(lambda x, y : x+y) \\\n",
    "#    .saveAsTextFile(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_FN='SAT_Results.csv'\n",
    "HSD_FN='DOE_High_School_Directory_2014-2015.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat = sc.textFile(SAT_FN).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'DBN'),\n",
       " (1, 'SCHOOL NAME'),\n",
       " (2, 'Num of SAT Test Takers'),\n",
       " (3, 'SAT Critical Reading Avg. Score'),\n",
       " (4, 'SAT Math Avg. Score'),\n",
       " (5, 'SAT Writing Avg. Score')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(sat.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('02M047', (16, 400)),\n",
       " ('21K410', (475, 437)),\n",
       " ('30Q301', (98, 440)),\n",
       " ('17K382', (59, 374))]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractScore(pid, rows):\n",
    "    if pid == 0:\n",
    "        next(rows)\n",
    "    import csv\n",
    "    for fields in csv.reader(rows):\n",
    "        if fields[2] != 's':\n",
    "            yield (fields[0], (int(fields[2]), int(fields[4])))\n",
    "    \n",
    "    \n",
    "satScore =sat.mapPartitionsWithIndex(extractScore)\n",
    "satScore.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'dbn'),\n",
       " (1, 'school_name'),\n",
       " (2, 'boro'),\n",
       " (3, 'building_code'),\n",
       " (4, 'phone_number'),\n",
       " (5, 'fax_number'),\n",
       " (6, 'grade_span_min'),\n",
       " (7, 'grade_span_max'),\n",
       " (8, 'expgrade_span_min'),\n",
       " (9, 'expgrade_span_max'),\n",
       " (10, 'bus'),\n",
       " (11, 'subway'),\n",
       " (12, 'primary_address_line_1'),\n",
       " (13, 'city'),\n",
       " (14, 'state_code'),\n",
       " (15, 'zip'),\n",
       " (16, 'website'),\n",
       " (17, 'total_students'),\n",
       " (18, 'campus_name'),\n",
       " (19, 'school_type'),\n",
       " (20, 'overview_paragraph'),\n",
       " (21, 'program_highlights'),\n",
       " (22, 'language_classes'),\n",
       " (23, 'advancedplacement_courses'),\n",
       " (24, 'online_ap_courses'),\n",
       " (25, 'online_language_courses'),\n",
       " (26, 'extracurricular_activities'),\n",
       " (27, 'psal_sports_boys'),\n",
       " (28, 'psal_sports_girls'),\n",
       " (29, 'psal_sports_coed'),\n",
       " (30, 'school_sports'),\n",
       " (31, 'partner_cbo'),\n",
       " (32, 'partner_hospital'),\n",
       " (33, 'partner_highered'),\n",
       " (34, 'partner_cultural'),\n",
       " (35, 'partner_nonprofit'),\n",
       " (36, 'partner_corporate'),\n",
       " (37, 'partner_financial'),\n",
       " (38, 'partner_other'),\n",
       " (39, 'addtl_info1'),\n",
       " (40, 'addtl_info2'),\n",
       " (41, 'start_time'),\n",
       " (42, 'end_time'),\n",
       " (43, 'se_services'),\n",
       " (44, 'ell_programs'),\n",
       " (45, 'school_accessibility_description'),\n",
       " (46, 'number_programs'),\n",
       " (47, 'priority01'),\n",
       " (48, 'priority02'),\n",
       " (49, 'priority03'),\n",
       " (50, 'priority04'),\n",
       " (51, 'priority05'),\n",
       " (52, 'priority06'),\n",
       " (53, 'priority07'),\n",
       " (54, 'priority08'),\n",
       " (55, 'priority09'),\n",
       " (56, 'priority10'),\n",
       " (57, 'Location 1')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schools = sc.textFile(HSD_FN).cache()\n",
    "list(enumerate(schools.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01M450', 'Manhattan', 649),\n",
       " ('01M539', 'Manhattan', 1725),\n",
       " ('01M696', 'Manhattan', 560),\n",
       " ('02M374', 'Manhattan', 548)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractSchool(pid, rows):\n",
    "    if pid == 0:\n",
    "        next(rows)\n",
    "    \n",
    "    import csv\n",
    "    for fields in csv.reader(rows):\n",
    "        if len(fields) == 58 and fields[17].isdigit():\n",
    "            if int(fields[17]) > 500: \n",
    "                yield (fields[0], fields[2], int(fields[17]))\n",
    "    \n",
    "    \n",
    "largeSchool =schools.mapPartitionsWithIndex(extractSchool)\n",
    "largeSchool.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bronx', 470),\n",
       " ('Staten Island', 477),\n",
       " ('Manhattan', 514),\n",
       " ('Brooklyn', 487),\n",
       " ('Queens', 474)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "largeSchool.join(satScore) \\\n",
    "    .values() \\\n",
    "    .mapValues(lambda x: (x[0], ( x[0]*x[1]))) \\\n",
    "    .reduceByKey(lambda x,y: (x[0]+y[0],x[1]+y[1])) \\\n",
    "    .mapValues(lambda x: x[1]//x[0]) \\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|   DBN|ntakers| total|\n",
      "+------+-------+------+\n",
      "|02M047|     16|  6400|\n",
      "|21K410|    475|207575|\n",
      "|30Q301|     98| 43120|\n",
      "|17K382|     59| 22066|\n",
      "|18K637|     35| 13335|\n",
      "|32K403|     50| 18300|\n",
      "|09X365|     54| 18306|\n",
      "|11X270|     56| 22064|\n",
      "|05M367|     33| 12078|\n",
      "|14K404|     68| 24276|\n",
      "+------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfScores = spark.read.load(SAT_FN, format='csv', header = True, inferSchema=True)\n",
    "dfScores =dfScores.select('DBN', dfScores['Num of SAT Test Takers'].cast('int').alias('ntakers'),\n",
    "                          dfScores['`SAT Math Avg. Score`'].cast('int').alias('score')).na.drop()\n",
    "\n",
    "\n",
    "dfScores = dfScores.select('DBN', 'ntakers', (dfScores.score*dfScores.ntakers).alias('total'))\n",
    "\n",
    "dfScores.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|   dbn|     boro|\n",
      "+------+---------+\n",
      "|01M450|Manhattan|\n",
      "|01M539|Manhattan|\n",
      "|01M696|Manhattan|\n",
      "|02M374|Manhattan|\n",
      "|02M400|Manhattan|\n",
      "|02M408|Manhattan|\n",
      "|02M412|Manhattan|\n",
      "|02M413|Manhattan|\n",
      "|02M416|Manhattan|\n",
      "|02M418|Manhattan|\n",
      "|02M420|Manhattan|\n",
      "|02M425|Manhattan|\n",
      "|02M475|Manhattan|\n",
      "|02M489|Manhattan|\n",
      "|02M519|Manhattan|\n",
      "|02M520|Manhattan|\n",
      "|02M529|Manhattan|\n",
      "|02M542|Manhattan|\n",
      "|02M580|Manhattan|\n",
      "|02M600|Manhattan|\n",
      "+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSchools = spark.read.load(HSD_FN, format='csv', header = True, inferSchema=True)\n",
    "\n",
    "dfSchools = dfSchools.na.drop(subset=['boro'])\n",
    "dfSchools = dfSchools.filter(dfSchools['total_students']> 500)\n",
    "dfSchools = dfSchools.select('dbn', 'boro')\n",
    "\n",
    "dfSchools.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|         boro|               avg|\n",
      "+-------------+------------------+\n",
      "|       Queens| 474.3679400475233|\n",
      "|     Brooklyn|487.46256168204246|\n",
      "|Staten Island| 477.9099864130435|\n",
      "|    Manhattan| 514.9312780989081|\n",
      "|        Bronx|  470.198606271777|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfResults = dfSchools.join(dfScores, dfSchools.dbn==dfScores.DBN, how='inner')\n",
    "\n",
    "dfResults = dfResults.groupBy('boro').sum('ntakers', 'total')\n",
    "dfResults = dfResults.withColumn('avg', dfResults[2]/dfResults[1]) \\\n",
    "            .select('boro', 'avg')\n",
    "\n",
    "dfResults.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
